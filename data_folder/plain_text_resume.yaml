personal_information:
 name: "Huseyn"
 surname: "Abdullayev"
 date_of_birth: "24.07.1992"
 country: "Germany" 
 city: "Fulda"
 address: "Petersberger Straße 25"
 zip_code: "36037"
 phone_prefix: "+49"
 phone: "1520 600 79 37"
 email: "huseyn_abdullayev@outlook.de"
 github: "https://huseyna28.github.io/portfolio/"
 linkedin: "https://github.com/HuseynA28"

education_details:
 - education_level: "Master of Science"
   institution: "Universität Kassel"
   field_of_study: "Economic Behaviour and Governance"
   final_evaluation_grade: "2.3"
   start_date: "2019"
   year_of_completion: "2023"


 - education_level: "Bachelor of Science"
   institution: "Nakhchivan Staatliche Universität"
   field_of_study: "International Economics"
   final_evaluation_grade: "1.9"
   start_date: "2010"
   year_of_completion: "2014"

experience_details:
 - position: "Junior Data Consultant"
   company: "It-novum GmbH"
   employment_period: "09/2023 - Present"
   location: "Fulda, Germany"
   industry: "IT Consulting"
   key_responsibilities:
     - responsibility_1: "Developed end-to-end workflows using Snowflake, Docker, GitHub Actions and Jenkins for efficient ML model development and deployment"
     - responsibility_2: "Developed ThingsBoard dashboard enabling customers to track and monitor datasets effectively"
     - responsibility_3: "Utilized Snowpark for automating data loading and preprocessing in Snowflake, optimizing data processing"
   skills_acquired:
     - "MLflow"
     - "Snowpark"
     - "AWS S3"
     - "Docker"
     - "Jenkins"
     - "GitHub Actions"

 - position: "Data Scientist"
   company: "AUDI AG"
   employment_period: "03/2023 - 08/2023"
   location: "Ingolstadt, Germany"
   industry: "Automotive"
   key_responsibilities:
     - responsibility_1: "Modernized auto manufacturing process by transferring production logic from Excel to KNIME data pipelines, reducing manual effort by 20%"
     - responsibility_2: "Developed optimization algorithm for Supply Chain department improving production line efficiency by 25%"
     - responsibility_3: "Created XGBoost ML model for predicting engine durability with 92% accuracy"
   skills_acquired:
     - "KNIME"
     - "XGBoost"
     - "Supply Chain Optimization"
     - "Production Pipeline Automation"

 - position: "Big Data Analyst"
   company: "SVA System Vertrieb Alexander"
   employment_period: "11/2021 - 03/2023"
   location: "Wiesbaden, Germany" 
   industry: "IT Services"
   key_responsibilities:
     - responsibility_1: "Developed LightGBM model on Azure Synapse Analytics with 0.92 R-squared accuracy"
     - responsibility_2: "Built data pipeline for terabyte-scale dataset using Azure Databricks and Azure SQL"
     - responsibility_3: "Created customer segmentation analysis with RFM metrics in Azure"
   skills_acquired:
     - "Azure ML"
     - "Azure Synapse Analytics"
     - "Azure Databricks"
     - "Power BI"
     - "LightGBM"

projects:
 - name: "Snowflake MLOps"
   description: "CI/CD pipeline with Github, Docker, FastAPI, Snowflake, LinearRegression"
   link: "https://github.com/HuseynA28/Snowflake-MLOPS"

 - name: "AwsMlopsFaceApp"
   description: "Face detection app using Grafana, Snowflake, Docker, AWS, Railway APP"
   link: "https://github.com/HuseynA28/Deploying-ML-with-FastAPI-on-Docker-Kubernetes"

 - name: "ML Model Deployment on Docker and Kubernetes"
   description: "Deploying-ML-with-FastAPI-on-Docker-Kubernetes"
   link: "https://github.com/HuseynA28/Deploying-ML-with-FastAPI-on-Docker-Kubernetes"

 - name: "Sentiment-Analysis-with-Deep-Learning-and-MLflow"
   description: "Sentiment Analysis with Deep Learning and MLflow"
   link: "https://github.com/HuseynA28/Sentiment-Analysis-with-Deep-Learning-and-MLflow"



achievements:
 - name: "Best Worker of the Year"
   description: "Awarded by British Petroleum in 2017"
 - name: "MLOps Projects"
   description: "Successfully completed multiple end-to-end MLOps projects with high efficiency improvements"

certifications:
 - name: "SnowPro® Advanced Data Scientist"
   description: "Advanced certification in Snowflake Data Science capabilities"
 - name: "Microsoft Azure Data Scientist (DP-100)"
   description: "Expertise in Azure ML implementation and data science"
 - name: "Microsoft Azure Data Fundamentals (DP-900)"
   description: "Foundation level Azure data concepts certification"
 - name: "AWS Cloud Technical"
   description: "Technical proficiency in AWS cloud services"
 - name: "Databricks Lakehouse Fundamentals"
   description: "Fundamentals of Databricks Lakehouse architecture"

languages:
 - language: "Deutsch"
   proficiency: "B2"
 - language: "Englisch"
   proficiency: "Professional"
 - language: "Aserbaidschanisch"
   proficiency: "Native"
 - language: "Türkisch" 
   proficiency: "Native"

interests:
 - "Machine Learning"
 - "MLOps"
 - "Cloud Computing"

availability:
 notice_period: "6 months"

salary_expectations:
 salary_range_usd: "55000-60000"

self_identification:
 gender: "Male"
 pronouns: "he/him"
 veteran: "No"
 disability: "No"
 ethnicity: "Asian"

legal_authorization:
 eu_work_authorization: "Yes"
 us_work_authorization: "No"
 requires_us_visa: "Yes"
 requires_us_sponsorship: "Yes"
 requires_eu_visa: "No"
 legally_allowed_to_work_in_eu: "Yes"
 legally_allowed_to_work_in_us: "No"
 requires_eu_sponsorship: "No"
 canada_work_authorization: "No"
 requires_canada_visa: "Yes"
 legally_allowed_to_work_in_canada: "No"
 requires_canada_sponsorship: "Yes"
 uk_work_authorization: "No"
 requires_uk_visa: "Yes"
 legally_allowed_to_work_in_uk: "No"
 requires_uk_sponsorship: "Yes"

work_preferences:
 remote_work: "Yes"
 in_person_work: "Yes"
 open_to_relocation: "Yes"
 willing_to_complete_assessments: "Yes"
 willing_to_undergo_drug_tests: "NO"
 willing_to_undergo_background_checks: "No"